
import matplotlib.pyplot as plt
num_epochs = 50

train_losses = \
[0.009467369876801968, 0.005212935619056225, 0.5091400146484375, 0.48908132314682007, 0.4773382842540741, 0.46815967559814453, 0.4603222608566284, 0.45321139693260193, 0.44675394892692566, 0.44084474444389343, 0.4353337287902832, 0.4297875165939331, 0.4248119294643402, 0.4200168550014496, 0.415323942899704, 0.41078799962997437, 0.4061753749847412, 0.40174365043640137, 0.39736446738243103, 0.39299318194389343, 0.3887866139411926, 0.3845703601837158, 0.38032209873199463, 0.37614476680755615, 0.37210318446159363, 0.3682934641838074, 0.3643091320991516, 0.36048245429992676, 0.3566208481788635, 0.3528914153575897, 0.34915632009506226, 0.34533819556236267, 0.341672420501709, 0.3380213975906372, 0.33461710810661316, 0.3311474323272705, 0.32767271995544434, 0.3243241310119629, 0.3210204839706421, 0.31786835193634033, 0.31474223732948303, 0.311684250831604, 0.30856579542160034, 0.3056999146938324, 0.3028337359428406, 0.30000513792037964, 0.2972034811973572, 0.2942601442337036, 0.29151779413223267, 0.28874558210372925, 
0.2859604060649872]
val_losses = \
[1.061972045898438, 0.5864192247390747, 0.5608428120613098, 0.5498300194740295, 0.5427768230438232, 0.5392743945121765, 0.537485659122467, 0.536327064037323, 0.5367408394813538, 0.5377141237258911, 0.5385862588882446, 0.542243480682373, 0.5461212992668152, 0.5493887662887573, 0.5543912053108215, 0.5572198033332825, 0.561547577381134, 0.5651272535324097, 0.5691223740577698, 0.572706401348114, 0.5769336223602295, 0.5808268785476685, 0.585266649723053, 0.5904461741447449, 0.5950919985771179, 0.5996891260147095, 0.604629397392273, 0.6091783046722412, 0.6152331233024597, 0.6217482089996338, 0.6275454759597778, 0.6323484182357788, 0.6375085711479187, 0.6434825658798218, 0.6495969295501709, 0.6559352874755859, 0.6621171832084656, 0.6688516139984131, 0.6747391819953918, 0.6810840964317322, 0.6889946460723877, 0.693355143070221, 0.7003023028373718, 0.7074192762374878, 0.7143152952194214, 0.7179755568504333, 0.7234767079353333, 0.7288222908973694, 0.7360827922821045, 0.7421680092811584, 0.7484129071235657]
val_accuracies = \
[0.6101207590569293, 0.7479394287904926, 0.7598236534406747, 0.7626988690818478, 0.7623155069963581, 0.7642323174238068, 0.7661491278512556, 0.7674908951504696, 0.7665324899367453, 0.7655740847230209, 0.7665324899367453, 0.7644239984665516, 0.7651907226375312, 0.765382403680276, 0.7628905501245927, 0.7630822311673375, 0.7625071880391029, 0.7611654207398888, 0.7628905501245927, 0.7626988690818478, 0.7619321449108684, 0.760973739697144, 0.7580985240559709, 0.7582902050987157, 0.7582902050987157, 0.7571401188422465, 0.7559900325857772, 0.7542649032010734, 0.7548399463293081, 0.7506229633889209, 0.748897834004217, 0.7479394287904926, 0.7492811960897068, 0.7485144719187272, 0.7479394287904926, 0.7471727046195131, 0.7467893425340234, 0.745830937320299, 0.7460226183630438, 0.7462142994057888, 0.7435307648073606, 0.744489170021085, 0.7435307648073606, 0.7423806785508913, 0.7414222733371669, 0.7406555491661875, 0.7402721870806978, 0.7408472302089323, 0.7389304197814837, 0.7385470576959938, 0.7389304197814837]


plt.plot(range(num_epochs+1), train_losses, label='Training loss')
plt.plot(range(num_epochs+1), val_losses, label='Validation loss')
plt.plot(range(num_epochs+1), val_accuracies, label='Prediction accuracy')

plt.xlabel('Epoch (training time)')
plt.legend()
plt.show()